# Video-Captioning
MLDS2017 Project2
## Quick start
1. Download MSVD dataset which provides features extracted by VGG that is pretrained on the ImageNet.
Link: https://drive.google.com/file/d/0B18IKlS3niGFNlBoaHJTY3NXUkE/view (provided by MLDS2017) and put MSVD dataset under video-captioning folder

2. Create two .txt files and name first one "sample_output_testset.txt", second one "sample_output_peer_review.txt". The peer view one is for MLDS2017 peer review so if you just want to have a quick start, please remove line  
